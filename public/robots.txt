# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# Allow all crawlers access to all content by default.
User-agent: *
Allow: /

# Disallow Next.js specific paths that are not meant for direct crawling.
Disallow: /_next/
Disallow: /api/

Sitemap: https://eatwise.evotyindia.me/sitemap.xml